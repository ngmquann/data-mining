import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler


def preprocess_before_split(df: pd.DataFrame):  
    # Loáº¡i bá» customerID náº¿u cÃ³ (khÃ´ng cÃ³ giÃ¡ trá»‹ dá»± Ä‘oÃ¡n)
    if 'customerID' in df.columns:
        df = df.drop('customerID', axis=1)
    
    # Xá»­ lÃ½ TotalCharges (chuyá»ƒn tá»« object sang numeric)
    if 'TotalCharges' in df.columns:
        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    
    # ===== 1) Xá»­ lÃ½ Missing Values =====
    # Numerical columns â†’ thay báº±ng median
    num_cols = df.select_dtypes(include=["int64", "float64"]).columns
    df[num_cols] = df[num_cols].fillna(df[num_cols].median())
    
    # Categorical columns â†’ thay báº±ng mode
    cat_cols = df.select_dtypes(include=["object"]).columns
    df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])
    
    # ===== 2) Encoding (Chuyá»ƒn dá»¯ liá»‡u chá»¯ sang sá»‘) =====
    # Label Encoding cho cÃ¡c biáº¿n nhá»‹ phÃ¢n (2 giÃ¡ trá»‹)
    binary_cols = ['gender','Partner','Dependents','PhoneService','PaperlessBilling','Churn']
    le = LabelEncoder()
    for col in binary_cols:
        if col in df.columns:
            df[col] = le.fit_transform(df[col])
    
    # One-hot Encoding cho cÃ¡c biáº¿n cÃ³ nhiá»u giÃ¡ trá»‹
    df = pd.get_dummies(df, drop_first=True)
    
    # ===== 3) Feature Engineering (Táº¡o thuá»™c tÃ­nh má»›i) =====
    if set(["MonthlyCharges", "tenure"]).issubset(df.columns):
        # Tá»•ng doanh thu tá»« khÃ¡ch hÃ ng
        df["Revenue"] = df["MonthlyCharges"] * df["tenure"]
        # Chi phÃ­ trung bÃ¬nh má»—i thÃ¡ng
        df["AvgMonthlyCharge"] = df["TotalCharges"] / (df["tenure"] + 1)
    
    # KhÃ¡ch hÃ ng lÃ¢u nÄƒm (> 12 thÃ¡ng)
    df["LongTermCustomer"] = (df["tenure"] > 12).astype(int)
    # KhÃ¡ch hÃ ng cÃ³ chi phÃ­ cao
    df["HighCharge"] = (df["MonthlyCharges"] > df["MonthlyCharges"].median()).astype(int)
    
    return df


def prepare_data(df: pd.DataFrame, target_column="Churn"):
    """TÃ¡ch dá»¯ liá»‡u thÃ nh X_train, X_test, y_train, y_test sau khi tiá»n xá»­ lÃ½ Ä‘áº§y Ä‘á»§."""
    
    # Tiá»n xá»­ lÃ½ (chÆ°a scaling)
    df = preprocess_before_split(df)
    
    X = df.drop(target_column, axis=1)
    y = df[target_column]
    
    # TÃ¡ch train/test vá»›i tá»‰ lá»‡ 80-20
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # ===== 4) Scaling SAU KHI split (trÃ¡nh data leakage) =====
    scale_cols = ['tenure','MonthlyCharges','TotalCharges','Revenue','AvgMonthlyCharge']
    scale_cols = [c for c in scale_cols if c in X_train.columns]  # trÃ¡nh lá»—i thiáº¿u cá»™t
    
    scaler = StandardScaler()
    # Fit trÃªn train set, transform cáº£ train vÃ  test
    X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])
    X_test[scale_cols] = scaler.transform(X_test[scale_cols])  # chá»‰ transform, khÃ´ng fit
    
    return X_train, X_test, y_train, y_test


# Cháº¡y Ä‘á»™c láº­p Ä‘á»ƒ kiá»ƒm tra module
if __name__ == "__main__":
    df = pd.read_csv("data/Customer_Churn.csv")
    X_train, X_test, y_train, y_test = prepare_data(df)
    print("âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t!")
    print(f"ğŸ“Š Train size: {X_train.shape} | Test size: {X_test.shape}")
    print(f"ğŸ¯ PhÃ¢n bá»‘ Churn - Train: {y_train.value_counts().to_dict()}")